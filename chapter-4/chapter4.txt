Chapter 4: Text-to-SQL, enhance
your LLM responses by
integrating data from the
Database
Text-to-SQL is a task in natural language processing (NLP) that automatically
generates Structured Query Language (SQL) queries from natural language text.
This makes it easier for non-technical users to access and analyze data. With the
advancement of Large Language Models (LLMs) like GPT-4, LLaMA, and Gemini,
this field has seen significant improvements in natural language understanding and
the ability to produce high-quality SQL queries. In this chapter, we will explore the
entire process of using LLMs for Text-to-SQL, helping readers enhance their database
query optimization skills.
What is Text-to-SQL?
Text-to-SQL is a technology that enables users to convert natural language text into
executable SQL code, allowing them to query databases using plain English or other
human-readable languages. With Text-to-SQL, users can simply input their queries
in everyday language, and the system will automatically generate the corresponding
SQL code, which can then be executed against a database to retrieve results.
For example, consider a database schema with two entities: track and album, as
shown below.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 119
Figure 4.1
If you ask a question like, How many tracks are in the album named "Fireball"?,
the LLM takes both the user’s question and the database schema information as input,
then generates an SQL query as output. This generated SQL query can be executed
against the database to retrieve the data and provide an answer such as, There are
7 tracks in the album named "Fireball.".
Text-to-SQL typically involves a few components:
1. User prompt: The User asks a question in natural language, such as “How
many tracks are in the album named “Fireball”?”.
2. Knowledge of the database schema: the structure of the database schema is
provided as an input parameter to the LLM.
3. Natural language processing: The LLM acts as an NLP unit, analyzing the
user’s input and identifying the intent behind their query
4. SQL Generation: The LLM analyzes the user’s input, identifying entities,
relationships, and actions within it. This analysis enables the system to generate
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 120
a tailored SQL query that can be executed against a database to retrieve the
specific information requested.
5. Agent or application for executing the SQL: Depending on the framework
or agent used by the system, the generated SQL query is executed against the
database, and the result is returned to the LLM for summarization.
The overall Text-to-SQL process is illustrated in Figure 4.2.
Figure 4.2
Patterns of using Text-to-SQL typically involve various approaches and scenarios
where this technology can be applied. Here are a few key patterns wide used in
productions:
1. Ad hoc analysis in Natural language: This pattern is common in business
intelligence and data analysis, where users need quick answers without writing
complex SQL queries such as What were the sales figures last month?.
2. Data validation: Checking data for consistency and accuracy, such as Verify
that all employee salaries are within a valid range..
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 121
3. Automated Reporting: Text-to-SQL widley uses to automate regular reports
by converting scheduled natural language descriptions into SQL queries, which
then generate the necessary data for the reports.
4. Customization and Fine-Tuning for specific domain: Text-to-SQL systems
can be fine-tuned for specific domains (e.g., healthcare, finance) to better handle
domain-specific terminology and queries. These systems can be customized to
understand and generate SQL queries based on particular database schemas,
improving accuracy and relevance.
Challenges of Text-to-SQL
While Text-to-SQL offers new opportunities to leverage LLMs for integrating with
databases, making it easier for non-technical users and allowing developers to focus
on higher-level tasks instead of writing boilerplate SQL code, it also introduces some
limitations and challenges. The technical challenges and limitations of Text-to-SQL
can be summarized as follows:
1. Handling ambiguity in queries: Natural language is often ambiguous, making
it difficult to determine the intended meaning or context. Queries like What is
the average salary of employees who have worked for more than 5 years?
require the system to understand the nuances of natural language and map it
to a valid SQL query.
2. Contextual understanding and Named Entity Recognition: Text-to-SQL
systems need to understand the context in which a question is asked, including
the database schema and relationships between entities. Moreover, identifying
specific entities such as tables, columns, and relationships within the database
schema can be challenging.
3. Query generation: Converting a natural language query into a valid SQL
query that retrieves the desired data can be complex, especially when dealing
with joins, subqueries, or aggregations.
4. Security and privacy: Automatically generated SQL queries may inadver-
tently expose sensitive data if not properly secured. It’s crucial to ensure that
these queries adhere to privacy and security protocols.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 122
5. Lack of high-quality training data to improve accuracy: High-quality
training data enables LLMs to learn complex relationships between entities.
Without this data, the model may only generate simple SQL queries, which is
why most general-purpose LLMs struggle to produce complex SQL queries.
If you’re interested in the challenges of Text-to-SQL, I highly recommend checking
out this recent review paper. It discusses various limitations and provides concrete
references.
LLM for Text-to-SQL
As you can imagine, we need LLMs specifically designed for SQL generation tasks
because they are fine-tuned to understand database schemas, generate complex
and optimized SQL queries, handle domain-specific nuances, and reduce ambiguity
in natural language inputs. These capabilities are essential for building reliable,
accurate, and efficient Text-to-SQL systems.
There are several LLMs that have already been developed, fine-tuned, and specifi-
cally designed for SQL generation. Let’s take a look at them in the following table.
LLM Parameter Memory footprint Description
Codestral 22b 13GB Codestral is Mistral
AI’s first-ever code
model designed for
code generation
tasks. It is a 22B
model.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 123
LLM Parameter Memory footprint Description
Sqlcoder 15b 9GB SQLCoder is a 15B
parameter model
that is fine-tuned
on a base StarCoder
model. It slightly
outperforms
gpt-3.5-turbo for
natural language to
SQL generation
tasks on the
sql-eval framework,
and outperforms
popular
open-source
models. It also
significantly
outperforms
text-davinci-003, a
model that’s more
than 10 times its
size.
Duckdb-
nsql
7b 3.8GB This model is based
on Meta’s original
Llama-2 7B model
and further
pre-trained on a
dataset of general
SQL queries and
then fine-tuned on
a dataset composed
of DuckDB
text-to-SQL pairs
I tested all three LLMs mentioned above with the same database schema and prompts.
The results show that Codestral LLM generates better SQL queries than the others. If
you have 16 GB of free RAM, I recommend using Codestral, as it is fast and generates
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 124
precise SQL queries efficiently.
System design patterns of using Text-to-SQL
with examples
System design patterns for using Text-to-SQL involve structuring components and
workflows to effectively leverage the capabilities of Text-to-SQL systems to meet
business needs. While the term system design patterns may not be entirely precise
in this context, this section will explore the most common use cases addressed by
Text-to-SQL, guided with examples.
For demonstration purposes, I will utilize the Langchain framework as a development
tool and leverage the Chinook Database as a representative sample data set. To
generate SQL queries, I will employ the Codestral LLM.
To get started, let’s prepare the necessary infrastructure by setting up the database
and download the Codestral LLM.
Step 1: Install SQLite
For installation and configuration instructions, please refer to the appropriate section
in Chapter 1.
Step 2: Set Up Chinook Database as a source of data
You can obtain the Chinook.db file by downloading it from our GitHub repository
and copying it into your Jupyter notebook workspace. Alternatively, you can set up
the database from scratch using the instructions provided in this link.
With the database file in place, you can interact with it using SQLite. You’ll be able
to execute SQL queries and manipulate data within the database. Additionally, you
can connect to the Chinook.db file using DBeaver, a popular database management
tool. This will allow you to explore the tables and their structures in a more visual
and intuitive way. The following diagram illustrates the structure of the Chinook
database:
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 125
Figure 4.3
Step 3: Run Ollama LLM runner with Codestral
ollama run codestral:latest
The above command will pull the latest version of the Codestral LLM and run. We’re
now ready to proceed.
Design pattern 1. Generating and executing SQL
queries
The most common use case for Text-to-SQL is enabling non-technical users to
create SQL queries against a database, which can then be executed by the user to
retrieve results. Alternatively, users may prefer to have the generated SQL query
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 126
run automatically against the database, with the system providing a summary of the
results in human-readable language through the LLM. If we illustrated the process,
it will be very similar to the figure 4.4.
Figure 4.4
Step 1: Create a Jupyter Notebook
Open your JupyterLab environment by navigating to the URL where it’s running.
Click on the New button to create a fresh notebook. You can choose from various
templates or start with an empty one. In this notebook, add the following lines of
code:
!pip install langchain
!pip install langchain-community
The above lines of code tell Jupyter Notebook to execute the pip install langchain
command in the shell, which will download and install the LangChain library.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 127
Tip
We strongly advise installing and configuring Conda as described in
Chapter 1, a popular package manager, along with JupyterLab, a web-based
interactive environment, to get the most out of your sandbox.
Step 2: Import necessary libraries
from langchain_community.llms import Ollama
import sqlite3
from langchain_community.utilities import SQLDatabase
These Python code imports three modules and defines a context for working with
natural language processing (NLP) and database interactions:
• from langchain_community.llms import Ollama:
– This line imports the Ollama class from the langchain_community.llms
module.
• import sqlite3:
– This line imports the built-in Python sqlite3 module, which provides a
lightweight database engine.
• from langchain_community.utilities import SQLDatabase:
– This line imports the SQLDatabase class from the langchain_-
community.utilities module. The SQLDatabase class provides utility
functions for interacting with SQLite databases, making it easier to
perform common database operations like querying and inserting data.
Step 3: Initializes an instance of the Ollama class
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 128
llm = Ollama(
base_url='http://YOUR_IP_ADDRESS_HERE:11434'
model="codestral:latest"
,
,
temperature=0
)
The code snippet initializes an instance of the Ollama class, which is a part of the
LangChain framework. Here’s what each parameter means:
• base_url='http://YOUR_IP_ADDRESS_HERE:11434'
– Specify the URL where the Ollama runner is running. Use your IP address
or localhost if Ollama is running on the same machine as Jupyter Lab.
• model="codestral:latest"
– Defines the specific model to be used. In this case, “codestral:latest” will
be used to generate SQL queries.
• temperature=0
– Sets the temperature parameter for the model’s responses. The temperature
controls the randomness of the output:
* Low temperature (close to 0): Results in more deterministic and
focused responses.
* Higher temperature (e.g., 1): Leads to more varied and creative
responses.
Step 4: Connect to the database
db = SQLDatabase.from_uri("sqlite:///Chinook.db")
print(db.dialect)
print(db.get_usable_table_names())
Here’s a breakdown of each line:
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 129
• SQLDatabase.from_uri("sqlite:///Chinook.db"): This line creates an in-
stance of the SQLDatabase class using a URI. The from_uri method initializes
the SQLDatabase object and establishes a connection to this SQLite database.
Warning
The Chinook.db file should be placed in the same directory as your Jupyter
Notebook.
• print(db.dialect): It’s prints the dialect attribute of the db object. The dialect
attribute provides information about the database type or SQL dialect that the
SQLDatabase instance is using.
• print(db.get_usable_table_names()): This line prints the result of the get_-
usable_table_names() method. This method retrieves and returns a list of table
names in the database that are accessible and can be used for querying. It allows
you to see which tables are available in the Chinook.db database.
Now, let’s see what happens when we run the notebook. If everything is set up
correctly, you should see results similar to those shown below.
sqlite
['Album'
eLine'
,
'Artist'
,
,
'MediaType'
,
'Customer'
,
'Playlist'
,
'Employee'
'Genre'
,
'PlaylistTrack'
,
'Invoice'
,
'Track']
,
'Invoic\
Step 5: Generate SQL query
Add the following lines of code.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 130
from langchain.chains import create_sql_query_chain
chain = create_sql_query_chain(llm, db)
response = chain.invoke({"question": "How many track in Album named 'Fi\
reball?"})
response
Here, I use the LangChain library to create a chain that generates SQL queries based
on natural language questions and then invokes this chain to get a response from the
database. Here’s a breakdown of each line:
• from langchain.chains import create_sql_query_chain: This imports the
create_sql_query_chain function from the langchain.chains module. This
function is used to create a chain that integrates a language model (LLM) with
a database to handle SQL query generation.
• chain = create_sql_query_chain(llm, db): This line creates an instance of a
query chain by calling create_sql_query_chain, passing in two arguments:
– llm: The language model object created previously that will generate SQL
queries based on natural language input.
– db: The database object created before. This function combines the LLM
and the database into a query chain that can process natural language
questions and convert them into SQL queries.
• response = chain.invoke({"question": "How many track in Album
named 'Fireball?"}): This line invokes the query chain with a natural
language question. The invoke method processes the question, generates the
corresponding SQL query using the LLM.
• response: This line outputs the SQL query generated by the LLM.
To view the result, just run the notebook. If everything works correctly, you should
get an output similar to the one shown below.
"SELECT COUNT(T1.TrackId) FROM Track AS T1 INNER JOIN Album AS T2 ON T1\
.AlbumId = T2.AlbumId WHERE T2.Title = 'Fireball'"
Now that you’ve seen how to generate the query, let’s take it a step further. You
can manually run the SQL query by executing it in your database management
tool. Alternatively, you can use the Langchain SQLDatabase utilities to simplify the
process. To do this, add a new cell to your notebook and paste the following code:
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 131
db.run(response)
Run this cell from the notebook menu bar. It should print the result of the query
execution:
'[(7,)]'
You can also try the following prompts to get the result as a SQL query:
1. "question": "How many employees are there who lives in Calgary?"
2. "question": "What is the name of the Artist of Album named 'Fireball'?"
3. "question": "Who is the composer of the Album named 'Chemical
Wedding'?"
4. "question": "Who is the composer of the track Chemical Wedding?"
Tip
Keep in mind that not all prompts will result in a valid SQL query. If you
encounter an error, try refining your prompt and re-running the notebook
to see if it produces the desired results.
So far, you’ve seen how to manually execute a SQL query generated by the model.
Now, let’s take advantage of the LLM’s capabilities: instead of just generating a
query, we can ask it to return the result in human-friendly language. To generate
a human-friendly response, we’ll utilize the Langchain PromptTemplate class. This
will allow us to define a template for our query and then have the LLM fill in the
details.
Step 6: Generate a human language response with the LLM.
Add the following pseudo code to a new cell.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 132
from langchain_community.tools.sql_database.tool import QuerySQLDataBas\
eTool
execute_query = QuerySQLDataBaseTool(db=db)
write_query = create_sql_query_chain(llm, db)
from operator import itemgetter
This above code sets up a sophisticated pipeline that converts a natural language
question into an SQL query, executes it on a database, and then processes the result
to provide a natural language answer. Here’s the line-by-line explanations of the
code:
• from langchain_community.tools.sql_database.tool import
QuerySQLDataBaseTool: This imports the QuerySQLDataBaseTool class,
which provides tools for interacting with an SQL database within the
LangChain framework. This tool allows you to execute SQL queries against a
specified database.
• execute_query = QuerySQLDataBaseTool(db=db): Creates an instance of
QuerySQLDataBaseTool and connects it to the db object created earliar to run
SQL queries on the database.
• write_query = create_sql_query_chain(llm, db): This give line creates a
query chain that uses the provided language model (llm) and the database
connection (db) to convert natural language input into an SQL query. The
resulting SQL query can then be executed against the database.
• from operator import itemgetter: imports itemgetter from Python’s
operator module. itemgetter is a utility that retrieves a specific field (in this
case, “query”) from a dictionary or object.
Now, add a few more imports to a new cell.
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
• StrOutputParser: Parses the output from the language model as a string.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 133
• PromptTemplate: A template for structuring prompts passed to the language
model.
• RunnablePassthrough: A utility that allows data to pass through a sequence of
operations without being altered.
Now that we’ve defined our prompt template, we’re all set to utilize the Langchain
PromptTemplate class in our code.
answer_prompt = PromptTemplate.from_template(
"""Given the following user question, corresponding SQL query, and \
SQL result, answer the user question.
Question: {question}
SQL Query: {query}
SQL Result: {result}
Answer: """
)
• This creates a PromptTemplate for generating a prompt that will instruct the
language model on how to answer the user’s question. The template includes
placeholders for the question, SQL query, and the result from the query.
Let’s invoke the answer on chain.
answer = answer_prompt | llm | StrOutputParser()
chain = (
RunnablePassthrough.assign(query=write_query).assign(
result=itemgetter("query") | execute_query
)
| answer
)
• The above lines of codes chains together the answer_prompt, the language
model (llm), and the StrOutputParser. This chain is responsible for taking
the structured prompt, passing it through the language model, and parsing the
output into a final answer.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 134
Last step: let’s run the entire pipeline by invoking the Langchain instance. Just add
this final line of code to complete the process.
chain.invoke({"question": "How many track in Album named 'Fireball'?"})
This line invokes the entire chain with a user-provided question. The chain processes
the question by converting it into an SQL query, executing the query, and then
generating a natural language answer based on the result. The specific question
asked here is: "How many tracks are in the album named 'Fireball'?"
Be patient, as this process may take a short time to finish. You’ll know it’s done when
the output appears, which should look like the example shown below.
'The answer to the user question is:\n\nThere are 7 tracks in the album\
named "Fireball"
'
.
In this way, with just a few simple steps, you can generate and execute SQL queries
on your database using a local LLM. In any case, the complete source code of this
notebook is available on our GitHub book repository.
Design pattern 2. Using Agent’s for error handling and
ensure correctness
In the previous approach, if an error occurs or the generated SQL query is invalid,
there is no way to recover from the process. Additionally, the generated SQL code is
executed only once, regardless of whether the answer is correct.
This gap can be bridged by using an AI Agent. An AI Agent is a software component
that can automate and optimize the interaction between users and LLMs. Such an
agent has the ability to analyze SQL databases by transforming natural language
queries into SQL commands. Moreover, it can act as an intermediary between
users or applications and the database, enabling tasks such as query execution, data
retrieval, and updates.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 135
Info
We’ve dedicated an entire chapter to AI Agents. For now, think of agents
as predefined modules that can automate tasks.
The LangChain SQL Agent exemplifies these capabilities. One of the key features of
this SQL agent is its ability to query the database as many times as needed to provide
a comprehensive answer to the user’s question. This means that even if the initial
query doesn’t yield the desired result, the agent can automatically refine its search
and iterate through multiple queries to ensure that the final response accurately
addresses the user’s inquiry.
By integrating the Langchain SQL Agent into our system, we can significantly
improve the accuracy and completeness of our responses, making it an invaluable
tool for providing top-notch user experiences.
Figure 4.5.
As an example, for this section, we will explore the possibilities of the LangChain
SQL Agent for auto-recovery from errors and self-optimization of SQL queries.
We will continue to extend our previous notebook by adding new code.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 136
Step 1: Add the SQL agent code into the notebook
from langchain_community.agent_toolkits import create_sql_agent
from langchain.agents.agent_types import AgentType
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
First import necessary libraries.
• create_sql_agent: This function is used to create a SQL agent, which allows
natural language queries to be converted into SQL commands.
• AgentType: defines different types of agents.
• SQLDatabaseToolkit: A toolkit that provides necessary tools for interacting
with SQL databases.
Then, create the SQL Agent as shown below:
agent_executor = create_sql_agent(
llm=llm,
toolkit=SQLDatabaseToolkit(db=db, llm=llm),
verbose=True,
agent_type="zero-shot-react-description"
,
handle_parsing_errors=True
)
Here’s a detailed explanation of this above part:
• llm=llm: Specifies the large language model (LLM) to be used by the SQL agent.
In our case, it’s codestral
• toolkit=SQLDatabaseToolkit(db=db, llm=llm): Initializes the
SQLDatabaseToolkit with a specific database (db) and the language model
(llm).
• verbose=True: This setting makes the agent provide detailed logs of what it is
doing, which can be useful for debugging and understanding how the agent is
processing queries.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 137
• agent_type="zero-shot-react-description": This specifies the type of agent.
A “zero-shot-react-description” agent can react to natural language inputs
without needing pre-training on those specific tasks, meaning it can generate
SQL queries from user prompts on-the-fly.
• handle_parsing_errors=True: This enables the agent to handle errors in query
parsing gracefully, allowing it to recover from parsing errors without crashing.
Now, invoke the agent with a prompt.
agent_executor.invoke("How many track in Album named 'Fireball'?")
• agent_executor.invoke: This method is used to execute a natural language
query. In this example, the query asks for how many track in the Album named
Fireball. The agent will interpret this question, generate the appropriate SQL
query using the LLM, execute it against the connected database, and check the
results. If the result is not correct, the agent will attempt to optimize and re-
execute the query up to three times to return the desired result.
Here’s the entire output of the execution of SQL Agent.
> Entering new SQL Agent Executor chain...
Action: sql_db_list_tables
Action Input:Album, Artist, Customer, Employee, Genre, Invoice, Invoice\
Line, MediaType, Playlist, PlaylistTrack, TrackBased on the list of tab
les provided by `sql_db_list_tables`, I think the most relevant tables
for this question would be `Album` and`Track`
. Therefore, I should que
ry their schema to see what columns are available.
Action: sql_db_schema
Action Input: Album, Track
CREATE TABLE "Album" (
"AlbumId" INTEGER NOT NULL,
"Title" NVARCHAR(160) NOT NULL,
"ArtistId" INTEGER NOT NULL,
PRIMARY KEY ("AlbumId"),
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 138
FOREIGN KEY("ArtistId") REFERENCES "Artist" ("ArtistId")
)
/*
3 rows from Album table:
AlbumId Title ArtistId
1 For Those About To Rock We Salute You 1
2 Balls to the Wall 2
3 Restless and Wild 2
*/
CREATE TABLE "Track" (
"TrackId" INTEGER NOT NULL,
"Name" NVARCHAR(200) NOT NULL,
"AlbumId" INTEGER,
"MediaTypeId" INTEGER NOT NULL,
"GenreId" INTEGER,
"Composer" NVARCHAR(220),
"Milliseconds" INTEGER NOT NULL,
"Bytes" INTEGER,
"UnitPrice" NUMERIC(10, 2) NOT NULL,
PRIMARY KEY ("TrackId"),
FOREIGN KEY("MediaTypeId") REFERENCES "MediaType" ("MediaTypeId"),
FOREIGN KEY("GenreId") REFERENCES "Genre" ("GenreId"),
FOREIGN KEY("AlbumId") REFERENCES "Album" ("AlbumId")
)
/*
3 rows from Track table:
TrackId Name AlbumId MediaTypeId GenreId Composer Milliseconds \
Bytes UnitPrice
1 For Those About To Rock (We Salute You) 1 1 1 Angus Young, Ma\
lcolm Young, Brian Johnson 343719 11170334 0.99
2 Balls to the Wall 2 2 1 U. Dirkschneider, W. Hoffmann, H. F\
rank, P. Baltes, S. Kaufmann, G. Hoffmann 342562 5510424 0.99
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 139
3 Fast As a Shark 3 2 1 F. Baltes, S. Kaufman, U. Dirkscneider \
& W. Hoffman 230619 3990994 0.99
*/Based on the schema of the `Album` and`Track` tables, I think the mo\
st relevant column for this question would be `Title` in the `Album` ta
ble and`Name` in the `Track` table. Therefore, I should query these co
lumns to see if there are any albums with a title named 'Fireball'
.
Action: sql_db_query_checker
Action Input: SELECT Title FROM Album WHERE Title = 'FireballSELECT Tit\
le FROM Album WHERE Title = 'Fireball'The query seems correct, but I'll
make sure to double-check it. Let me run it through the checker.
Action: sql_db_query_checker
Action Input: SELECT Title FROM Album WHERE Title = 'FireballSELECT Tit\
le FROM Album WHERE Title = 'Fireball'The query seems correct, but I'll
make sure to double-check it. Let me run it through the checker.
Action: sql_db_query_checker
Action Input: SELECT Title FROM Album WHERE Title = 'FireballSELECT Tit\
le FROM Album WHERE Title = 'Fireball'It seems like there's an issue wi
th the query. The error is likely due to a missing closing parenthesis
at the end of the query.
Let me try rewriting and re-checking the query:
Action: sql_db_query_checker
Action Input: SELECT Title FROM Album WHERE Title = 'FireballSELECT Tit\
le FROM Album WHERE Title = 'Fireball'It seems like there's an issue wi
th the query. The error is likely due to a missing closing parenthesis
at the end of the query.
Let me try rewriting and re-checking the query:
Action: sql_db_query_checker
Action Input: SELECT Title FROM Album WHERE Title = 'FireballSELECT Tit\
le FROM Album WHERE Title = 'Fireball'It seems like there's an issue wi
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 140
th the query. The error is likely due to a missing closing parenthesis
at the end of the query.
Let me try rewriting and re-checking the query:
Action: sql_db_query_checker
Action Input: SELECT Title FROM Album WHERE Title = 'FireballSELECT Tit\
le FROM Album WHERE Title = 'Fireball'It seems like there's an issue wi
th the query. The error is likely due to a missing closing parenthesis
at the end of the query.
Action: sql_db_query
Action Input: SELECT COUNT(T1.TrackId) FROM Track AS T1 INNER JOIN Albu\
m AS T2 ON T1.AlbumId = T2.AlbumId WHERE T2.Title = 'Fireball'
Thought: I now know the final answer.
Final Answer: There are 7 tracks in the album named "Fireball"
.
> Finished chain.
{'input': 'How many track in Album named 'Fireball?'
are 7 tracks in the album named "Fireball"'}
,
'output': 'There \
Take a look at the output of the agent’s execution. First, the agent selects the
relevant tables to answer the query. Next, it generates and executes the SQL query.
Initially, it finds that the query seems correct but performs further validation to
ensure accuracy. The agent then repeats the validation process, confirming that the
query appears correct after re-checking. At some points, the agent identifies an issue
with the query, specifically a missing closing parenthesis, which makes the query
syntactically incorrect. The agent rewrites and re-executes the SQL query. Once the
agent confirms that the query result is correct, it finalizes the result by invoking the
LLM and prints the result in human-readable language.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 141
Tip
To control the execution loop and time of the SQL agent, you can use the
optional parameters max_iterations and max_execution_time.
The LangChain SQL Agent is a powerful tool with several additional features that
help optimize and improve results. Some of these features include:
• Dynamic Few-Shot prompting: Enhances query accuracy by using examples
to guide the agent in generating more relevant SQL queries.
• Handling High-Cardinality columns: Efficiently manages columns with a
large number of unique values, improving query performance and relevance.
• Retriever tool: Facilitates better data retrieval by helping the agent identify
and fetch relevant information from the database.
As always, you can find the complete source code in our book’s GitHub repository.
Design pattern 3. Text-To-SQL with RAG
The previous two patterns we learned earlier have some limitations. They can’t
handle large volumes of database entity information, and they’re not equipped to
handle domain-specific knowledge. That’s where the Text-to-SQL RAG comes in.
Text-to-SQL Retrieval-Augmented Generation (RAG) is a technique that combines
natural language processing with information retrieval to generate SQL queries from
text input or DDL schemas. By augmenting the generation process with relevant
data or documents, this approach can overcome some of the limitations of previous
methods.
This RAG technique is particularly useful in the following scenarios
• Handling large or dynamic schemas: When dealing with large, complex, or
frequently changing database schemas, it can be difficult to generate accurate
SQL queries without access to the latest schema information in real-time. RAG
can help by dynamically retrieving the most up-to-date schema details and
using them to generate SQL queries.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 142
• Domain-specific knowledge: If the SQL generation needs to account for
domain-specific terminology or abbreviations, RAG can retrieve relevant do-
main documents or context to improve the accuracy of the generated SQL. For
example, in a healthcare sector, translating Find all patients diagnosed with
HTN to SQL query would benefit from retrieval of documents that clarify HTN
stands for hypertension.
• Complex query generation: When you have a natural language query that
involves complex conditions or multiple joins across different tables, Text-to-
SQL RAG can help by retrieving relevant context or schema details before
generating the SQL. For example, Example: A query like Which sales agent
made the most in sales in 2010? might require specific schema details and
relationship information that RAG can retrieve.
• Improving query accuracy: RAG can improve query accuracy where regularly
updated databases where column names or data types might change. It can
enhance the accuracy of SQL generation by ensuring that the generated queries
are consistent with the latest available data or schema information, reducing the
chances of incorrect queries due to outdated context.
So far, we’ve used Langchain SQL agent to achieve query generation and error
handling. However, when using Langchain with RAG, there are some limitations
to be aware of, such as needing to dynamically insert only the most relevant
information into the prompt, which can be uncomfortable to use.
Fortunately, an open-source framework named Vanna.ai is available, specifically
designed for text-to-SQL conversion with RAG. This alternative may offer a more
streamlined experience.
In the final section of this chapter, I will leverage Vanna to use RAG for text-to-SQL
conversion.
Vanna provides a diagram (see Figure 4.6) illustrating its internal process.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 143
Figure 4.6
According to the resources provided by the framework, Vanna operates in two simple
steps:
1. Train your model: This step involves generating embeddings and storing the
embeddings along with metadata in a vector database, such as ChromaDB.
2. Ask a question: In this stage, Vanna retrieves relevant DDL and references
from the vector database to construct a prompt. This prompt is then sent to the
LLM to generate the SQL query.
Before getting started, let’s summarize the components that will be used for devel-
oping examples:
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 144
Components Description
Vanna Framework This is the core tool that will facilitate natural
language to SQL conversion.
ChromaDB A vector database that will be used to store
embeddings and metadata generated during
the training phase.
Ollama LLM runner. Our LLM will be codestral 7b
SQLite Database A sample database (Chinook_Sqlite.sqlite,
available on GitHub Repository) will be used
to connect, query, and train the Vanna model.
Flask Web Application Optional, A simple web interface using Flask
will be set up to interact with the Vanna
model.
These components will work together to enrich our model based on the DDL scripts
for generating SQL queries depending on your questions.
Warning
Note that there’s currently a bug in Vanna preventing the use of a remote
Ollama runner. To work around this issue, please run your Ollama runner
locally on the same machine where you plan to execute the Python script.
Alternatively, if you’d like to test connecting to a remote Ollama runner,
you can try running the following magic command from the notebook:
%env OLLAMA_HOST="REMOTE_OLLAMA_IP:PORT".
Step 1: Install the required dependencies
!pip install 'vanna[ollama,chromadb]'
The above line installs the vanna package along with its optional dependencies,
ollama and chromadb.
Step 2: Import classes
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 145
from vanna.ollama import Ollama
from vanna.chromadb.chromadb_vector import ChromaDB_VectorStore
Here, line 1-2 imports the Ollama class from vanna.ollama and the ChromaDB_-
VectorStore class from vanna.chromadb.chromadb_vector.
Step 3: Define a class
class MyVanna(ChromaDB_VectorStore, Ollama):
def __init__(self, config=None):
ChromaDB_VectorStore.__init__(self, config=config)
Ollama.__init__(self, config=config)
• Class MyVanna inherits from both ChromaDB_VectorStore and Ollama.
• The constructor initializes both parent classes, passing an optional config
parameter.
Step 4: Instantiating the python class MyVanna
vn = MyVanna(config={'model': 'codestral'})
This line of codes creates an instance of MyVanna, passing a configuration dictionary
that specifies using the codestral model.
The code snippet also generates a chrome.sqlite3 file in the notebook workspace
directory, containing all the embedding information from the database schema. The
schema of the chrome.sqlite3 database includes entities that are shown in the ER
diagram below.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 146
chrome db ER diagram
Step 5: Connecting to an SQLite Database
vn.connect_to_sqlite('Chinook_Sqlite.sqlite')
This line connects the vn instance to an SQLite database named
Chinook_Sqlite.sqlite. Please note that the Chinook_Sqlite.sqlite file must be
placed in the same directory as your Jupyter Notebook.
Step 6: Removing Existing Training Data
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 147
existing_training_data = vn.get_training_data()
if len(existing_training_data) > 0:
for _, training_data in existing_training_data.iterrows():
vn.remove_training_data(training_data["id"])
This block checks if there is any existing training data and removes it if found.
The method get_training_data() retrieves the current training data, and remove_-
training_data() removes each entry by its ID. This ensures that the training starts
with a clean state.
Step 7: Retrieving the Database Schema (DDL)
df_ddl = vn.run_sql("SELECT type, sql FROM sqlite_master WHERE sql is n\
ot null")
This line runs a SQL query to fetch the DDL information, which includes the SQL
statements used to define the structure of the database, from the sqlite_master table
of the Chinook database.
Step 8: Training the Model on DDL Data
for ddl in df_ddl['sql'].to_list():
vn.train(ddl=ddl)
This loop iterates through each DDL statement and trains the MyVanna instance on
these statements. It likely helps the model understand the structure of the database
and how to generate relevant SQL queries.
Warning
This step must be executed once to train the data. If you want to retrain the
data on the same datasets, you need to remove the existing trained data first.
Otherwise, you might encounter an error similar to: Number of requested
results 10 is greater than number of elements in index 2, updating
n_results = 2.
Step 9: Retrieving and displaying training Data
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 148
training_data = vn.get_training_data()
training_data
These lines fetch the current training data after the training steps and display it. This
allows inspection of what data the model has been trained on.
If you execute this notebook now, you will obtain a similar outcome to the one
displayed below.
Figure 4.7
Please note that Vanna’s capabilities extend beyond training DDL scripts for
databases. It can also utilize database indexes as part of its training data.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 149
Warning
Before executing the Notebook, please ensure that your Ollama LLM runner
is already up and running with Codestral.
Step 10: Generating and running a SQL Query
vn.ask(question="shows the total sales per country. Which country's cus\
tomers spent the most?", allow_llm_to_see_data=True)
This section shows how the model generates a SQL query from a natural language
input and then executes that query. The parameter allow_llm_to_see_data=True
controls whether the LLM can access specific database information when generating
the SQL query. When set to True, the LLM is allowed to see relevant data (metadata
or schema information) from the database to improve the accuracy of the generated
SQL query.
Info
Alternatively, you can use the following commands to generate and execute
SQL queries separately: sql = vn.generate_sql("Question") to generate
an SQL query based on the question and vn.run_sql(sql) to execute the
generated SQL query
Now, execute this notebook. After executing it, you will obtain a visual representa-
tion of the results in graphical form.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 150
Figure 4.8
total sales 523,06 and the country USA
You can ask following question based on the Chinook DB:
1. Show the most purchased track of 2013.
2. Which sales agent made the most in sales in 2010?
3. Show the invoices of customers who are from Brazil.
Step 11: Additional improvements
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 151
There are a few methods available to train a model with different types of input:
Data Definition Language (DDL) statements, business-specific documentation, and
SQL queries.
1. Training with a DDL Statement.
Assume you are working with a very large dataset, and your analyst sends you new
entities to generate SQL queries based on questions. Instead of retraining the models
from scratch, you can train only on the new entities’ DDL scripts and start working
with them.
vn.train(ddl="""
CREATE TABLE [Invoice_archive]
(
[InvoiceId] INTEGER NOT NULL,
[CustomerId] INTEGER NOT NULL,
[InvoiceDate] DATETIME NOT NULL,
[BillingAddress] NVARCHAR(70),
[BillingCity] NVARCHAR(40),
[BillingState] NVARCHAR(40),
[BillingCountry] NVARCHAR(40),
[BillingPostalCode] NVARCHAR(10),
[Total] NUMERIC(10,2) NOT NULL,
CONSTRAINT [PK_Invoice] PRIMARY KEY ([InvoiceId]),
FOREIGN KEY ([CustomerId]) REFERENCES [Customer] ([CustomerId])
ON DELETE NO ACTION ON UPDATE NO ACTION
);
""")
By training Vanna using a DDL script alone, you can leverage its capabilities without
needing to connect to the underlying database. This approach allows Vanna to gain
a deep understanding of the schema, enabling it to accurately generate SQL queries
that involve specific tables.
2. Training with Business-Specific Documentation.
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 152
vn.train(documentation="Our business defines OTIF score as the percenta\
ge of orders that are delivered on time and in full")
This method adds business-specific terminology or definitions to the Vanna model’s
training data. It helps the model understand business concepts and jargon that might
not be inherently obvious.
3. Training with a SQL Query.
vn.train(sql="SELECT Milliseconds / 1000.0 AS Seconds, * FROM Track WHE\
RE Seconds >= 250;")
This above command can add an example SQL query to the training data, which
can help improve the model’s understanding of how to construct queries based on
certain patterns or requirements. Such a way, the model will better understand how
to construct similar SQL queries when asked in natural language, especially queries
that involve time conversions, filtering, and selecting specific fields.
By incorporating various training data types, Vanna becomes more adept at generat-
ing accurate and contextually relevant SQL queries based on natural language input.
It understands both the structural aspects of the database and the semantic meaning
of business terms and operations.
Furthermore, Vanna offers a built-in Flask web application that enables interactive
querying capabilities. This interface allows users to ask questions directly to the
system, receiving accurate SQL query responses in real-time.
To start the web application, run the following code:
from vanna.flask import VannaFlaskApp
app = VannaFlaskApp(vn, allow_llm_to_see_data=True)
app.run()
This brings us to the end of the chapter. Feel free to experiment with the Vanna web
app beyond what we’ve covered in this book — we sure you’ll find it worth exploring!
Chapter 4: Text-to-SQL, enhance your LLM responses by integrating data from the
Database 153
Conclusion
In this chapter, we explored the art of converting natural language into SQL
queries. We examined the intricacies of understanding user queries and transforming
them into executable SQL code. The key takeaway is that effective text-to-SQL
generation requires a deep understanding of both human language and database
query structures.
Additionally, we discussed how to integrate multiple components within a text-to-
SQL system to create a robust pipeline capable of handling complex queries. This
integration involved combining entity recognition with paraphrasing to generate
accurate SQL queries from user inputs.
We introduced the Langchain library and Vanna as tools that facilitate the rapid
development and integration of such systems. Their API allows for the easy
incorporation of various modules, such as SQL database utilities and query checkers,
into our pipeline.
Throughout this chapter, we demonstrated how to address the challenges inherent in
text-to-SQL conversion by leveraging state-of-the-art NLP techniques and machine
learning algorithms. As we continue to enhance these systems, they will become
increasingly adept at translating complex user queries into accurate and efficient
SQL code.